{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAX Reconstruction Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload descriptions to pull into reconstruction experiment\n",
    "\n",
    "One record per description\n",
    "\n",
    "<!-- \n",
    "**Original metadata** for each domain are uploaded individually (i.e. with a single sweep of the notebook from here to TOPUP BATCH).\n",
    "\n",
    "**Topup metadata** are uploaded to a separate database, but done all together.\n",
    "This uploads a single record for every one participant missing from that batch. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import os, sys\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import ast\n",
    "\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.path import Path\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import random\n",
    "from functools import reduce\n",
    "\n",
    "from scipy.stats import norm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import copy\n",
    "import importlib\n",
    "\n",
    "# import urllib library\n",
    "from urllib.request import urlopen\n",
    "\n",
    "### Add Paths\n",
    "\n",
    "## root paths\n",
    "curr_dir = os.getcwd()\n",
    "proj_dir = os.path.abspath(os.path.join(curr_dir,'..')) ## u\\e relative paths\n",
    "\n",
    "## add helpers to python path\n",
    "import sys\n",
    "if os.path.join(proj_dir, 'stimuli') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir, 'stimuli'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data storage setup\n",
    "\n",
    "(If we need to get data about stims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket_path_template = \"https://lax-{}-{}-all.s3.amazonaws.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdomains = {\n",
    "    'structures' :  ['bridge', 'castle', 'house', 'city'],\n",
    "    'drawing' :  ['nuts-bolts','wheels','furniture','dials']\n",
    "}\n",
    "\n",
    "domains = list(subdomains.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "structures, bridge\n"
     ]
    }
   ],
   "source": [
    "domain = domains[0]\n",
    "subdomain = subdomains[domain][0]\n",
    "print(domain + ', ' + subdomain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to mongo\n",
    "\n",
    "import pymongo as pm\n",
    "\n",
    "# set vars \n",
    "auth = pd.read_csv('../../auth.txt', header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'cogtoolslab.org' ## experiment server ip address\n",
    "\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1')\n",
    "db = conn['stimuli']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get stimulus data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stim_df(domain, subdomain):\n",
    "\n",
    "    experiment_name = 'lax_{}_{}_10'.format(domain, subdomain)\n",
    "\n",
    "    # generate bucket path\n",
    "    s3_bucket_path = s3_bucket_path_template.format(domain, subdomain)\n",
    "\n",
    "    if domain == 'structures':\n",
    "        # read manifest data\n",
    "        df = pd.read_csv(s3_bucket_path + 'df_{}.csv'.format(subdomain))\n",
    "\n",
    "        # estimated complexity\n",
    "        df.loc[0:50, 'estimated_complexity'] = 'low'\n",
    "        df.loc[50:, 'estimated_complexity'] = 'high'\n",
    "\n",
    "        # assign grouping column\n",
    "    #     df['group'] = np.where(df['train'], 'train', 'test')\n",
    "        df['group'] = df['estimated_complexity']\n",
    "\n",
    "        # assign id column\n",
    "        df['stim_id'] = df['structure_number'] \n",
    "\n",
    "\n",
    "    elif domain == 'drawing':\n",
    "\n",
    "        # read manifest data\n",
    "        df = pd.read_csv(s3_bucket_path + 'manifest.csv'.format(subdomain))\n",
    "\n",
    "        # estimated complexity\n",
    "        df.loc[0:50, 'estimated_complexity'] = 'low'\n",
    "        df.loc[50:, 'estimated_complexity'] = 'high'\n",
    "\n",
    "        # assign grouping column\n",
    "    #     df['group'] = df['data_split']\n",
    "        df['group'] = df['estimated_complexity']\n",
    "\n",
    "        # assign id column\n",
    "        df['stim_id'] = df['stim_id'].apply(lambda x: x[-3:])\n",
    "        \n",
    "    df['experiment_name'] = experiment_name\n",
    "    df['s3_bucket_path'] = s3_bucket_path\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_stim_df(domain, subdomain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in description data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read results csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descriptions = pd.read_csv('../../results/csv/lax_corpus_1k_cogsci22.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the 10 descriptions from each architect/ describer trials into 2 sets of 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_group(df):\n",
    "    indices = list(range(0, len(df)))\n",
    "    np.random.shuffle(indices)\n",
    "    groups = (pd.Series(indices) < len(df)/2).map({True: 'A', False: 'B'})\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metadatum_for_group(df):\n",
    "    \n",
    "    trials = []\n",
    "    stimIDs = []\n",
    "    stimURLs = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "\n",
    "        trials.append({\n",
    "            'stimID' : row.stimId,\n",
    "            'stimURL': row.stimURL,\n",
    "            'subdomain': row.subdomain,\n",
    "            'descriptionGameID': row.gameID,\n",
    "            'descriptionTrialNum': row.trial_num,\n",
    "            'description' :\n",
    "                {\n",
    "                'whats': ast.literal_eval(row.whats),\n",
    "                'wheres': ast.literal_eval(row.wheres)\n",
    "                },\n",
    "            })\n",
    "        stimURLs.append(row.stimURL)\n",
    "        stimIDs.append(row.stimId)\n",
    "        \n",
    "    metadatum = {\n",
    "        'domain': domain,\n",
    "        'stimIDs': stimIDs,\n",
    "        'stimURLs': stimURLs,\n",
    "        'trials' : trials,\n",
    "        'numGames': 0,\n",
    "        'games': [],\n",
    "        'experimentType': 'reconstruction',\n",
    "        'experimentName': 'lax_reconstruction_towers_dev',\n",
    "        'versionInd': version_ind\n",
    "    }\n",
    "\n",
    "    return metadatum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload = False\n",
    "\n",
    "for subdomain in subdomains['structures']:\n",
    "\n",
    "    # get correct subdomain\n",
    "    df_subdomain = df_descriptions[df_descriptions.subdomain==subdomain]\n",
    "\n",
    "    # groupby gameID\n",
    "    ppt_descriptions = df_subdomain.groupby('gameID')\n",
    "\n",
    "    metadata = []\n",
    "\n",
    "    # for each ppt\n",
    "    for gameID, group in ppt_descriptions:\n",
    "        group_labels = list(split_group(group)) #randomly split in two\n",
    "        group['group_labels'] = group_labels #label each with a group label\n",
    "        # and for each group create metadata\n",
    "        metadata += list(group.groupby('group_labels').apply(create_metadatum_for_group)) \n",
    "        \n",
    "    # upload to mongo\n",
    "    stim_coll_name = 'lax_reconstruction_stims_' + subdomain\n",
    "    print('uploading metadata to ' + stim_coll_name)\n",
    "    \n",
    "    if upload:\n",
    "        coll = db[stim_coll_name]\n",
    "        db.drop_collection(stim_coll_name)\n",
    "        for (i,j) in enumerate(metadata):\n",
    "            coll.insert_one(j)\n",
    "#             print('Inserted version {} of stimDict.'.format(j['versionInd']))\n",
    "        print('Uploaded version {} of {} metadata.'.format(j['versionInd'], subdomain))\n",
    "    else:\n",
    "        print('metadata created but not uploaded')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_coll_name = 'lax_reconstruction_stims_' + 'bridge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll = db[stim_coll_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(coll.find())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload a single metadatum of 5 trials (for all participants to recreate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_group(df):\n",
    "    indices = list(range(0, len(df)))\n",
    "    np.random.shuffle(indices)\n",
    "    groups = (pd.Series(indices) < len(df)/2).map({True: 'A', False: 'B'})\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metadatum_for_group(df):\n",
    "    \n",
    "    trials = []\n",
    "    stimIDs = []\n",
    "    stimURLs = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "\n",
    "        trials.append({\n",
    "            'stimID' : row.stimId,\n",
    "            'stimURL': row.stimURL,\n",
    "            'subdomain': row.subdomain,\n",
    "            'descriptionGameID': row.gameID,\n",
    "            'descriptionTrialNum': row.trial_num,\n",
    "            'description' :\n",
    "                {\n",
    "                'whats': ast.literal_eval(row.whats),\n",
    "                'wheres': ast.literal_eval(row.wheres)\n",
    "                },\n",
    "            })\n",
    "        stimURLs.append(row.stimURL)\n",
    "        stimIDs.append(row.stimId)\n",
    "        \n",
    "    metadatum = {\n",
    "        'domain': domain,\n",
    "        'stimIDs': stimIDs,\n",
    "        'stimURLs': stimURLs,\n",
    "        'trials' : trials,\n",
    "        'numGames': 0,\n",
    "        'games': [],\n",
    "        'experimentType': 'reconstruction',\n",
    "        'experimentName': 'lax_reconstruction_towers_dev',\n",
    "        'versionInd': version_ind\n",
    "    }\n",
    "\n",
    "    return metadatum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_ind = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading metadata to lax_reconstruction_stims_bridge\n",
      "Uploaded version 1 of bridge metadata.\n",
      "uploading metadata to lax_reconstruction_stims_castle\n",
      "Uploaded version 1 of castle metadata.\n",
      "uploading metadata to lax_reconstruction_stims_house\n",
      "Uploaded version 1 of house metadata.\n",
      "uploading metadata to lax_reconstruction_stims_city\n",
      "Uploaded version 1 of city metadata.\n"
     ]
    }
   ],
   "source": [
    "upload = True\n",
    "\n",
    "for subdomain in subdomains['structures']:\n",
    "\n",
    "    # get correct subdomain\n",
    "    df_subdomain = df_descriptions[df_descriptions.subdomain==subdomain]\n",
    "\n",
    "    # groupby gameID\n",
    "    ppt_descriptions = df_subdomain.groupby('gameID')\n",
    "\n",
    "    metadata = []\n",
    "\n",
    "    # for each ppt\n",
    "    for gameID, group in ppt_descriptions:\n",
    "        group_labels = list(split_group(group)) #randomly split in two\n",
    "        group['group_labels'] = group_labels #label each with a group label\n",
    "        # and for each group create metadata\n",
    "        metadata += list(group.groupby('group_labels').apply(create_metadatum_for_group)) \n",
    "        \n",
    "    # upload to mongo\n",
    "    stim_coll_name = 'lax_reconstruction_stims_' + subdomain\n",
    "    print('uploading metadata to ' + stim_coll_name)\n",
    "    \n",
    "    if upload:\n",
    "        coll = db[stim_coll_name]\n",
    "        db.drop_collection(stim_coll_name)\n",
    "        for (i,j) in enumerate(metadata[70:71]): # Take only last one\n",
    "            coll.insert_one(j)\n",
    "#             print('Inserted version {} of stimDict.'.format(j['versionInd']))\n",
    "        print('Uploaded version {} of {} metadata.'.format(j['versionInd'], subdomain))\n",
    "    else:\n",
    "        print('Metadata created but not uploaded')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lax_reconstruction_stims_city'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stim_coll_name = 'lax_reconstruction_stims_' + subdomains['structures'][3]\n",
    "stim_coll_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll = db[stim_coll_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('6245ea26896ace31dc2aecf4'),\n",
       "  'domain': 'structures',\n",
       "  'stimIDs': [115, 190, 174, 139, 6],\n",
       "  'stimURLs': ['https://lax-structures-city-all.s3.amazonaws.com/lax-structures-city-115-all.png',\n",
       "   'https://lax-structures-city-all.s3.amazonaws.com/lax-structures-city-190-all.png',\n",
       "   'https://lax-structures-city-all.s3.amazonaws.com/lax-structures-city-174-all.png',\n",
       "   'https://lax-structures-city-all.s3.amazonaws.com/lax-structures-city-139-all.png',\n",
       "   'https://lax-structures-city-all.s3.amazonaws.com/lax-structures-city-006-all.png'],\n",
       "  'trials': [{'stimID': 115,\n",
       "    'stimURL': 'https://lax-structures-city-all.s3.amazonaws.com/lax-structures-city-115-all.png',\n",
       "    'subdomain': 'city',\n",
       "    'descriptionGameID': '5032-b49130a3-5cda-434c-aadc-dc956e057838',\n",
       "    'descriptionTrialNum': 2.0,\n",
       "    'description': {'whats': ['2 blue blocks horizontally a few cms apart',\n",
       "      'place 4 blue blocks horizontally creating a line of 4.',\n",
       "      'Repeat the adding 4 bocks, then a further 2.',\n",
       "      'Finally add another 4 blocks.',\n",
       "      '3 bricks, then 2, then finally 1. ',\n",
       "      'with a blue block led horizontally to the right.',\n",
       "      'Place 2 blue blocks on top of the red laying horizontally.'],\n",
       "     'wheres': ['along a flat surface.',\n",
       "      'Then place 2 blocks a few cms apart horizontally.',\n",
       "      'Do this for 2 more layers.',\n",
       "      'Then create a roof shape',\n",
       "      'The second structure place 1 red block vertically',\n",
       "      'Place a red block on top of the blue, vertically.',\n",
       "      'Place 2 further blue blocks on top. And then 1 blue block led on top of these.']}},\n",
       "   {'stimID': 190,\n",
       "    'stimURL': 'https://lax-structures-city-all.s3.amazonaws.com/lax-structures-city-190-all.png',\n",
       "    'subdomain': 'city',\n",
       "    'descriptionGameID': '5032-b49130a3-5cda-434c-aadc-dc956e057838',\n",
       "    'descriptionTrialNum': 5.0,\n",
       "    'description': {'whats': ['Place 2 blue blocks laying on the ground.',\n",
       "      'Place 4 blue blocks horizontally on top. (2 blue blocks on top of each other) ',\n",
       "      'Finish 1 blue block on the very top. ',\n",
       "      'Place 4 blocks blocks vertically. Standing on top of the blue blocks either side. (1 block, gap, 2 red blocks, gap 1 red block)',\n",
       "      'repeat this for 3 layers. '],\n",
       "     'wheres': ['With 4 red blocks on top. (2 either red blocks stacked on top of each other either side, standing on the blue blocks) to create a U shape.',\n",
       "      'Repeat this for 2 more layers.',\n",
       "      'On the second structure place 4 blue blocks in the row, horizontally.',\n",
       "      'Place 4 blue blocks on top (2 blocks on the bottom, 2 on top)',\n",
       "      'Finish up by having 2 layers of blue blocks on the top. ']}},\n",
       "   {'stimID': 174,\n",
       "    'stimURL': 'https://lax-structures-city-all.s3.amazonaws.com/lax-structures-city-174-all.png',\n",
       "    'subdomain': 'city',\n",
       "    'descriptionGameID': '5032-b49130a3-5cda-434c-aadc-dc956e057838',\n",
       "    'descriptionTrialNum': 6.0,\n",
       "    'description': {'whats': ['4 red blocks standing vertically. Two blocks together, gap two more blocks together.',\n",
       "      'Repeat this for 2 layers.',\n",
       "      '3 more blocks on top, then 2, then 1 creating a roof shape.',\n",
       "      '4 blue blocks led on the bottom.',\n",
       "      'Continue this for 2 more layers.',\n",
       "      'Have a total of 8 blue blocks in two rows on top of each other.'],\n",
       "     'wheres': ['Then place 4 blue blocks horizontally along the top.',\n",
       "      'Place 4 blue blocks horizontally along the top creating a block of 8 blue blocks.',\n",
       "      'On the second structure create boxes. ',\n",
       "      'Then 4 red blocks vertically on top. ',\n",
       "      'Finish by creating a roof shape.',\n",
       "      'Then place 3, then 2, then 1 block on top of each other. ']}},\n",
       "   {'stimID': 139,\n",
       "    'stimURL': 'https://lax-structures-city-all.s3.amazonaws.com/lax-structures-city-139-all.png',\n",
       "    'subdomain': 'city',\n",
       "    'descriptionGameID': '5032-b49130a3-5cda-434c-aadc-dc956e057838',\n",
       "    'descriptionTrialNum': 8.0,\n",
       "    'description': {'whats': ['one blue block horizontally,',\n",
       "      'one blue block horizontally next to the red blocks',\n",
       "      '2 red blocks starting a 2nd layer,',\n",
       "      'further blocks to complete the pattern.',\n",
       "      'on the 4th layer place 4 blue blocks horizontally.',\n",
       "      'two more red blocks together a few cms apart from the first.',\n",
       "      'Continue this for a 2nd layer.'],\n",
       "     'wheres': ['with 2 red blocks stood next to it vertically.',\n",
       "      'then 2 red blocks stood vertically. ',\n",
       "      'with a blue block led horizontally next to it.',\n",
       "      'Continue this so you have a total of 3 layers.',\n",
       "      'On the second structure place two red blocks vertically together.',\n",
       "      'Next place 4 blue blocks horizontally along the top. ',\n",
       "      'Finally, lay a row of 4 blue blocks along the top of the structure. ']}},\n",
       "   {'stimID': 6,\n",
       "    'stimURL': 'https://lax-structures-city-all.s3.amazonaws.com/lax-structures-city-006-all.png',\n",
       "    'subdomain': 'city',\n",
       "    'descriptionGameID': '5032-b49130a3-5cda-434c-aadc-dc956e057838',\n",
       "    'descriptionTrialNum': 9.0,\n",
       "    'description': {'whats': ['4 blue blocks laying along the bottom.',\n",
       "      'Place 2 rows of 4 blue blocks along the top horizontally. ',\n",
       "      '1 blue block on the bottom, with a red block on top to the left.',\n",
       "      'a blue block led down on top to create nox.',\n",
       "      'Place 3 blue blocks on top to make a roof shape.'],\n",
       "     'wheres': ['with two red blocks stood vertically on top. (1 red block, few cms gap another red, red blocks next to it, few cms gap another red block.',\n",
       "      'On the second structure create a box shape.',\n",
       "      'Place another red block on the right, vertically.',\n",
       "      'Do this twice so you have 2 boxes next to each other.',\n",
       "      'Then place 2 blocks, then finally 1. ']}}],\n",
       "  'numGames': 0,\n",
       "  'games': [],\n",
       "  'experimentType': 'reconstruction',\n",
       "  'experimentName': 'lax_reconstruction_towers_dev',\n",
       "  'versionInd': 1}]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(coll.find())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby gameID\n",
    "ppt_descriptions = df_subdomain.groupby('gameID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = []\n",
    "\n",
    "# for each ppt\n",
    "for gameID, group in ppt_descriptions:\n",
    "    group_labels = list(split_group(group)) #randomly split in two\n",
    "    group['group_labels'] = group_labels #label each with a group label\n",
    "    metadata += list(group.groupby('group_labels').apply(create_metadatum_for_group)) # and for each group create metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subdomain = df_descriptions[df_descriptions.subdomain==subdomain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby gameID\n",
    "ppt_descriptions = df_subdomain.groupby('gameID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create record for each stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_ind = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = 'structures'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_domain = df_descriptions[df_descriptions.domain==domain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subdomain = df_descriptions[df_descriptions.subdomain==subdomain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_coll_name = 'lax_reconstruction_stims_' + subdomain\n",
    "print(stim_coll_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEMP: take 10 rows, keeping trials together\n",
    "\n",
    "# metadata = []\n",
    "\n",
    "# size = 20\n",
    "\n",
    "# i = 0\n",
    "# j = i + size\n",
    "\n",
    "# while j < len(df_domain):\n",
    "    \n",
    "#     trials = []\n",
    "#     stimIDs = []\n",
    "#     stimURLs = []\n",
    "    \n",
    "#     for _, row in df_domain.iloc[i:j].iterrows():\n",
    "\n",
    "#         trials.append({\n",
    "#             'stimID' : row.stimId,\n",
    "#             'stimURL': row.stimURL,\n",
    "#             'subdomain': row.subdomain,\n",
    "#             'descriptionGameID': row.gameID,\n",
    "#             'description' :\n",
    "#                 {\n",
    "#                 'whats': ast.literal_eval(row.whats),\n",
    "#                 'wheres': ast.literal_eval(row.wheres)\n",
    "#                 },\n",
    "#             })\n",
    "#         stimURLs.append(row.stimURL)\n",
    "#         stimIDs.append(row.stimId)\n",
    "\n",
    "#     metadata.append({\n",
    "#         'domain': domain,\n",
    "#         'stimIDs': stimIDs,\n",
    "#         'stimURLs': stimURLs,\n",
    "#         'trials' : trials,\n",
    "#         'numGames': 0,\n",
    "#         'games': [],\n",
    "#         'experimentType': 'reconstruction',\n",
    "#         'experimentName': 'lax_reconstruction_towers_dev',\n",
    "#         'versionInd': version_ind\n",
    "#     })\n",
    "    \n",
    "#     i = j\n",
    "#     j = j + size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to mongo\n",
    "\n",
    "import pymongo as pm\n",
    "\n",
    "# set vars \n",
    "auth = pd.read_csv('../../auth.txt', header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'cogtoolslab.org' ## experiment server ip address\n",
    "\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1')\n",
    "db = conn['stimuli']\n",
    "coll = db[stim_coll_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear metadata collection\n",
    "\n",
    "really_run = True;\n",
    "\n",
    "if really_run:\n",
    "    db.drop_collection(stim_coll_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now, iterate through each version and insert into mongo\n",
    "## loop through list of records and insert each into collection\n",
    "reallyRun = True\n",
    "if reallyRun:\n",
    "    for (i,j) in enumerate(metadata):\n",
    "        coll.insert_one(j)\n",
    "        print('Inserted version {} of stimDict.'.format(j['versionInd']))\n",
    "        clear_output(wait=True)\n",
    "\n",
    "else:\n",
    "    print('Did not insert any new data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_splits(df, \n",
    "                    n_families = 2,\n",
    "                    n_splits = 25,\n",
    "                    id_column = 'stim_id',\n",
    "                    grouping_column = 'group',\n",
    "                    verbose = False):\n",
    "    \n",
    "    # batch size = len(df) / n_splits\n",
    "    \n",
    "    groups = df[[id_column, grouping_column]]\n",
    "   \n",
    "    if verbose:\n",
    "        print(groups['group'].value_counts())\n",
    "    \n",
    "    X = df[id_column]\n",
    "    y = df[grouping_column]\n",
    "\n",
    "    for i in range(0, n_families):\n",
    "\n",
    "        # set up partitioning\n",
    "        skf = StratifiedKFold(n_splits=n_splits, \n",
    "                              random_state=i,  # tie random state to group num\n",
    "                              shuffle=True)\n",
    "\n",
    "        # apply partitioning and save to df\n",
    "        for split_num, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "            df.loc[test_index,'family_'+str(i)] = split_num\n",
    "    #         print(groups.loc[test_index])\n",
    "    \n",
    "    if verbose:\n",
    "        print(str(n_splits) + ' splits generated in each of ' + str(n_families) + ' families')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_splits(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To run multiple versions, upload the same metadate to separate collections, and update stimColName in configs accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "versionInd = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to mongo\n",
    "\n",
    "import pymongo as pm\n",
    "\n",
    "# set vars \n",
    "auth = pd.read_csv('../auth.txt', header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'cogtoolslab.org' ## experiment server ip address\n",
    "\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1')\n",
    "db = conn['stimuli']\n",
    "coll = db[df['experiment_name'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert to lists of stimulus names\n",
    "\n",
    "assert subdomain in df['experiment_name'][0]\n",
    "assert subdomain in coll.name\n",
    "\n",
    "metadata = []\n",
    "\n",
    "for f in range(0, n_families):\n",
    "    for s in range(0,n_splits):\n",
    "        stimIDs = list(df.groupby('family_'+str(f)).get_group(s)['stim_id'].apply(lambda x: str(x).zfill(3)))\n",
    "#         print(stim_numbers)\n",
    "        metadata.append(\n",
    "            {\n",
    "                'partitionFamily': f,\n",
    "                'splitNumber': s,\n",
    "                'stimIDs': stimIDs,\n",
    "                'stimURLS': [s3_bucket_path + \"lax-{}-{}-{}-{}.png\".format(domain,\n",
    "                                                              subdomain,\n",
    "                                                              (stimID if domain=='structures' else 'all'),\n",
    "                                                              ('all' if domain=='structures' else stimID))\\\n",
    "                            for stimID in stimIDs],\n",
    "                'ntrials': len(stimIDs),\n",
    "                'stimGroups': {n: df.groupby('family_'+str(f)).get_group(s).reset_index().loc[i,'group'] for i, n in enumerate(stimIDs)},\n",
    "                'numGames': 0,\n",
    "                'games': [],\n",
    "                'experimentType': 'corpus_collection',\n",
    "                'experimentName': df['experiment_name'][0],\n",
    "                's3_bucket_url': s3_bucket_path,\n",
    "                'versionInd': versionInd\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(coll.find())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test which versions have been run\n",
    "\n",
    "This grabs the dataframe created by data generator, to see which records need to be run more times.\n",
    "\n",
    "It wipes the metadata from mongo, and replaces it with individual records for each additional partition that needs to be run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOP-UP BATCH \n",
    "### REFRESH ALL DOMAINS BY RUNNING FROM HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate dataframe from data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdomains = {\n",
    "    'structures' :  ['bridge', 'castle', 'house', 'city'],\n",
    "    'drawing' :  ['nuts-bolts','wheels','furniture','dials']\n",
    "}\n",
    "\n",
    "domains = list(subdomains.keys())\n",
    "\n",
    "\n",
    "iteration_names = ['corpus_prolific_test','corpus_prolific_test_3']\n",
    "experiment_template = \"lax-{}-{}-corpus-{}-10\"\n",
    "condition = 'procedural'\n",
    "expected_trials = 10\n",
    "\n",
    "df_trial = pd.DataFrame()\n",
    "df_all = pd.DataFrame()\n",
    "\n",
    "db_data = conn['lax']\n",
    "\n",
    "for domain in domains:\n",
    "    col_name = 'lax_{}_corpus'.format(domain)\n",
    "    coll_data = db_data[col_name]\n",
    "    \n",
    "    for subdomain in subdomains[domain]:\n",
    "        \n",
    "        # get all data for subdomain from db\n",
    "        df_subdomain_all = pd.DataFrame(coll_data.find({\"$and\":[ {'iterationName' : { '$in': iteration_names }},\n",
    "                                          {'experimentName': experiment_template.format(domain, subdomain, condition)},\n",
    "                                         ]}))\n",
    "        \n",
    "        if len(df_subdomain_all) > 0:\n",
    "\n",
    "            df_subdomain_all['domain'] = domain\n",
    "            df_subdomain_all['subdomain'] = subdomain\n",
    "\n",
    "\n",
    "            # get metadata\n",
    "            df_subdomain_meta = df_subdomain_all[(df_subdomain_all.datatype == 'stim_metadata')]\\\n",
    "                                        [[\"gameID\",\"partitionFamily\",\"splitNumber\",\"stimIDs\", \"stimURLS\", \"stimGroups\",\n",
    "                                          \"numGames\",\"experimentType\",\"experimentName\",\"versionInd\"]]\n",
    "\n",
    "            # get trial data\n",
    "            df_subdomain_trial = df_subdomain_all[\\\n",
    "                      (df_subdomain_all.trial_type == 'stimuli-contextual-language-production') &\n",
    "                      (df_subdomain_all.datatype == 'trial_end') &\n",
    "                      (~pd.isna(df_subdomain_all.stimId))]\\\n",
    "                      [['datatype', 'iterationName', 'condition', 'domain', 'subdomain',\n",
    "                        'config_name', 'gameID', 'shuffle', 'trialOrder', 'rt', 'workerID', \n",
    "                        'trial_type', 'trial_index', 'time_elapsed', 'internal_node_id',\n",
    "                        'view_history', 'stimId', 'stimURL', 'responses']]\n",
    "\n",
    "            # merge metadata into trial data\n",
    "\n",
    "            # verify stim groups in metadata are correct\n",
    "            dicts = list(df_subdomain_all[df_subdomain_all.datatype=='stim_metadata']['stimGroups'])\n",
    "            stim_groups = reduce(lambda dict1, dict2: {**dict1, **dict2}, dicts)\n",
    "            stim_groups['demo_stim'] = 'demo_stim'\n",
    "            # assign stim groups from metadata\n",
    "            df_subdomain_trial['stim_group'] = df_subdomain_trial['stimId'].apply(lambda stim: stim_groups[stim])\n",
    "            df_subdomain_trial = df_subdomain_trial.merge(df_subdomain_meta, how='left', on='gameID')\n",
    "\n",
    "            # append subdomain data to main dataframe\n",
    "            df_trial = df_trial.append(df_subdomain_trial, ignore_index=True)\n",
    "            \n",
    "        else:\n",
    "            print('no data for ' + domain + '.' + subdomain)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial.loc[:, 'responses'] = df_trial.responses.apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mark completed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find full datasets\n",
    "did_complete = df_trial[df_trial.stim_group != 'demo_stim'].groupby(['gameID']).count()['datatype'] == expected_trials\n",
    "complete_dataset_gameIDs = list(did_complete[did_complete].index)\n",
    "\n",
    "df_trial.loc[:,'complete_dataset'] = False\n",
    "df_trial.loc[(df_trial.gameID.isin(complete_dataset_gameIDs)), 'complete_dataset'] = True\n",
    "\n",
    "# assign correct trial number\n",
    "df_trial.loc[:,'trial_num'] = df_trial.trial_index - min(df_trial.trial_index.unique()[1:]) + 1\n",
    "# assign practice trials to trial_num = 0\n",
    "df_trial.loc[df_trial.trial_num < 0,'trial_num'] = 0\n",
    "\n",
    "df_trial['rt_mins'] = df_trial.rt/(60*1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find ppts for whom no trials hit the 8 step limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: find datasets with no trials with 8 steps\n",
    "def get_responses(response):\n",
    "\n",
    "    whats = [key for key in response.keys() if 'what' in key]\n",
    "    wheres = [key for key in response.keys() if 'where' in key]\n",
    "\n",
    "    what_responses = [response[what] for what in whats]\n",
    "    where_responses = [response[where] for where in wheres]\n",
    "\n",
    "    return (what_responses, where_responses)\n",
    "\n",
    "df_trial.loc[:, 'response_lists'] = df_trial.responses.apply(get_responses)\n",
    "df_trial.loc[:, 'whats'] = df_trial.response_lists.apply(lambda x:x[0])\n",
    "df_trial.loc[:, 'wheres'] = df_trial.response_lists.apply(lambda x:x[1])\n",
    "df_trial.loc[:, 'n_steps'] = df_trial.whats.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark those that hit 8 step limit\n",
    "\n",
    "hit_8_step_limit = df_trial.groupby('gameID').n_steps.unique().apply(max) == 8\n",
    "\n",
    "df_trial.loc[:, 'ppt_hit_8_step_limit'] = (df_trial.iterationName == 'corpus_prolific_test') & \\\n",
    "                                        (df_trial.gameID.apply(lambda id: hit_8_step_limit[id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_trial[(df_trial.stimId!='demo_stim') &(df_trial.complete_dataset) & (~df_trial.ppt_hit_8_step_limit)]\\\n",
    "    .groupby(['subdomain','stimId'])['responses'].count().value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many complete datasets?\n",
    "df_trial[(df_trial.complete_dataset) & (df_trial.trial_num > 0) & (~df_trial.ppt_hit_8_step_limit)].groupby(['domain','subdomain'])['rt'].count()/expected_trials\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find how many of each partition/ split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on completeness and hitting 8 step limit (USED ONLY ONCE TO REMOVE DATA)\n",
    "# I.e. get complete datasets that are not from 'corpus_prolific_test' and hit the 8 step limit\n",
    "complete_counts = (df_trial[(df_trial.complete_dataset) & \n",
    "                            ~(df_trial.ppt_hit_8_step_limit)]\\\n",
    "                   .groupby(['subdomain','partitionFamily','splitNumber'])\\\n",
    "                   .count()/(expected_trials+1))['datatype'].reset_index()\n",
    "\n",
    "\n",
    "# # based on completeness only (i.e. )\n",
    "# complete_counts = (df_trial[df_trial.complete_dataset]\\\n",
    "#                    .groupby(['subdomain','partitionFamily','splitNumber'])\\\n",
    "#                    .count()/(expected_trials+1))['datatype'].reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### top-up incomplete splits by adding individual record for each into top-up stimuli collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a record in extra_metadata for each additional time a split needs to be run\n",
    "\n",
    "def create_extra_metadata(complete_counts, domain, subdomain, df, n_expected = 1):\n",
    "\n",
    "    experiment_name = df['experiment_name'][0]\n",
    "    s3_bucket_path = df['s3_bucket_path'][0]\n",
    "    \n",
    "    assert subdomain in experiment_name\n",
    "    \n",
    "    extra_metadata = []\n",
    "\n",
    "    for f in range(0, n_families):\n",
    "        for s in range(0, n_splits):\n",
    "\n",
    "            split_count = complete_counts[(complete_counts.partitionFamily == f) &\n",
    "                                          (complete_counts.splitNumber == s) & \n",
    "                                          (complete_counts.subdomain == subdomain)\n",
    "                                         ].reset_index()\n",
    "\n",
    "            if len(split_count) == 0:\n",
    "                n_completed = 0\n",
    "            else:\n",
    "                n_completed = split_count.loc[0,'datatype']\n",
    "\n",
    "            i = n_completed\n",
    "\n",
    "            while i < n_expected:\n",
    "\n",
    "                i = i + 1\n",
    "\n",
    "                stimIDs = list(df.groupby('family_'+str(f)).get_group(s)['stim_id'].apply(lambda x: str(x).zfill(3)))\n",
    "        #         print(stim_numbers)\n",
    "                extra_metadata.append(\n",
    "                    {\n",
    "                        'partitionFamily': f,\n",
    "                        'splitNumber': s,\n",
    "                        'stimIDs': stimIDs,\n",
    "                        'stimURLS': [s3_bucket_path + \"lax-{}-{}-{}-{}.png\".format(domain,\n",
    "                                                                      subdomain,\n",
    "                                                                      (stimID if domain=='structures' else 'all'),\n",
    "                                                                      ('all' if domain=='structures' else stimID))\\\n",
    "                                    for stimID in stimIDs],\n",
    "                        'ntrials': len(stimIDs),\n",
    "                        'stimGroups': {n: df.groupby('family_'+str(f)).get_group(s).reset_index().loc[i,'group'] for i, n in enumerate(stimIDs)},\n",
    "                        'numGames': 0,\n",
    "                        'games': [],\n",
    "                        'experimentType': 'corpus_collection',\n",
    "                        'experimentName': experiment_name,\n",
    "                        's3_bucket_url': s3_bucket_path,\n",
    "                        'versionInd': versionInd,\n",
    "                        'extra_metadata_index': i\n",
    "                    })\n",
    "            \n",
    "    return extra_metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "upload_to_mongo = False\n",
    "\n",
    "if not(upload_to_mongo):\n",
    "    print('NO DATA UPLOADED')\n",
    "\n",
    "for domain in domains:\n",
    "    for subdomain in subdomains[domain]:\n",
    "        \n",
    "        print(domain + ', ' + subdomain)\n",
    "        \n",
    "        df_stim = get_stim_df(domain, subdomain)\n",
    "        df_stim = generate_splits(df_stim)\n",
    "        \n",
    "        extra_metadata = create_extra_metadata(complete_counts,\n",
    "                                               domain, \n",
    "                                               subdomain,\n",
    "                                               df_stim,\n",
    "                                               n_expected = 1)\n",
    "        \n",
    "        stim_col_name = df_stim['experiment_name'][0]\n",
    "        top_up_stim_col_name = stim_col_name + '_top_up'\n",
    "        print(top_up_stim_col_name)\n",
    "        \n",
    "        if upload_to_mongo:\n",
    "            \n",
    "            db = conn['stimuli']\n",
    "            coll = db[top_up_stim_col_name]\n",
    "            \n",
    "            db.drop_collection(top_up_stim_col_name)\n",
    "            print('cleared stimuli/' + top_up_stim_col_name)\n",
    "            \n",
    "            for (i,j) in enumerate(extra_metadata):\n",
    "                coll.insert_one(j)\n",
    "#                 clear_output(wait=True)\n",
    "            \n",
    "            print(str(len(list(coll.find()))) + ' inserted into stimuli/' + top_up_stim_col_name)\n",
    "            \n",
    "        else:\n",
    "            print(str(len(extra_metadata)) + ' records to upload')\n",
    "        \n",
    "        print('')\n",
    "        # TODO insert into db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial[~df_trial.ppt_hit_8_step_limit].groupby(['subdomain','complete_dataset']).count()/11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to mongo\n",
    "import pymongo as pm\n",
    "\n",
    "# set vars \n",
    "auth = pd.read_csv('../../auth.txt', header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'cogtoolslab.org' ## experiment server ip address\n",
    "\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1')\n",
    "db = conn['lax']\n",
    "coll = db['lax_reconstruction_dev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(coll.find())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
